{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f0c12c2-fa90-413d-8313-cbf87a81b713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from concurrent.futures import ThreadPoolExecutor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7f1fc7c-aaaa-4722-8f0a-864febf1ccd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "def list_csv_files_in_zips(folder_path):\n",
    "    \"\"\"\n",
    "    Lists all CSV files within multiple ZIP archives in a folder.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): The path to the folder containing ZIP files.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary with ZIP file names as keys and a list of CSV file names as values.\n",
    "    \"\"\"\n",
    "    csv_files = {}\n",
    "    \n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.zip'):\n",
    "                zip_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                        csv_list = [name for name in zip_ref.namelist() if name.endswith('.csv')]\n",
    "                        if csv_list:\n",
    "                            csv_files[file] = csv_list\n",
    "                except Exception as e:\n",
    "                    csv_files[file] = f\"An error occurred: {e}\"\n",
    "    \n",
    "    return csv_files\n",
    "\n",
    "# Example usage\n",
    "folder_path = 'path/to/folder'\n",
    "csv_files = list_csv_files_in_zips(folder_path)\n",
    "for zip_file, csv_list in csv_files.items():\n",
    "    print(f\"CSV files in {zip_file}:\")\n",
    "    for csv_file in csv_list:\n",
    "        print(f\" - {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e351246-60a7-493b-b120-a139f2f3e96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/Users/thusondube/Downloads/itineraries_csv'\n",
    "csv_files = list_csv_files_in_zips(folder_path)\n",
    "for zip_file, csv_list in csv_files.items():\n",
    "    print(f\"CSV files in {zip_file}:\")\n",
    "    for csv_file in csv_list:\n",
    "        print(f\" - {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440579ff-1929-4efe-a673-26e39508faf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def list_csv_files_in_zips(folder_path):\n",
    "    \"\"\"\n",
    "    Lists all CSV files within multiple ZIP archives in a folder.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): The path to the folder containing ZIP files.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary with ZIP file names as keys and a list of CSV file names as values.\n",
    "    \"\"\"\n",
    "    csv_files = {}\n",
    "    \n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.zip'):\n",
    "                zip_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                        csv_list = [name for name in zip_ref.namelist() if name.endswith('.csv')]\n",
    "                        if csv_list:\n",
    "                            csv_files[zip_path] = csv_list\n",
    "                except Exception as e:\n",
    "                    csv_files[zip_path] = f\"An error occurred: {e}\"\n",
    "    \n",
    "    return csv_files\n",
    "\n",
    "def read_csv_from_zip(zip_path, csv_file):\n",
    "    \"\"\"\n",
    "    Reads a CSV file from a ZIP archive and returns it as a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    zip_path (str): The path to the ZIP file.\n",
    "    csv_file (str): The name of the CSV file within the ZIP archive.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the data from the CSV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            with zip_ref.open(csv_file) as f:\n",
    "                return pd.read_csv(f)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading {csv_file} from {zip_path}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def merge_csv_files_from_zips_to_dataframe(folder_path):\n",
    "    \"\"\"\n",
    "    Merges all CSV files within multiple ZIP archives in a folder into one DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): The path to the folder containing ZIP files.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the merged data from all CSV files.\n",
    "    \"\"\"\n",
    "    csv_files = list_csv_files_in_zips(folder_path)\n",
    "    merged_df = pd.DataFrame()\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for zip_path, csv_list in csv_files.items():\n",
    "            if isinstance(csv_list, list):\n",
    "                for csv_file in csv_list:\n",
    "                    futures.append(executor.submit(read_csv_from_zip, zip_path, csv_file))\n",
    "        \n",
    "        for future in futures:\n",
    "            df = future.result()\n",
    "            merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "# Example usage\n",
    "folder_path = '/Users/thusondube/Downloads/itineraries_csv'\n",
    "merged_df = merge_csv_files_from_zips_to_dataframe(folder_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f179f8e8-a10d-42c2-ab21-57d1e9f23ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/Users/thusondube/Downloads/itineraries_csv'\n",
    "merged_df = merge_csv_files_from_zips_to_dataframe(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cc09d13-df1b-49dd-80bd-914e9f0fd41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>legId</th>\n",
       "      <th>searchDate</th>\n",
       "      <th>flightDate</th>\n",
       "      <th>startingAirport</th>\n",
       "      <th>destinationAirport</th>\n",
       "      <th>travelDuration</th>\n",
       "      <th>isBasicEconomy</th>\n",
       "      <th>isRefundable</th>\n",
       "      <th>isNonStop</th>\n",
       "      <th>totalFare</th>\n",
       "      <th>...</th>\n",
       "      <th>segmentsArrivalTimeEpochSeconds</th>\n",
       "      <th>segmentsArrivalTimeRaw</th>\n",
       "      <th>segmentsArrivalAirportCode</th>\n",
       "      <th>segmentsDepartureAirportCode</th>\n",
       "      <th>segmentsAirlineName</th>\n",
       "      <th>segmentsAirlineCode</th>\n",
       "      <th>segmentsEquipmentDescription</th>\n",
       "      <th>segmentsDurationInSeconds</th>\n",
       "      <th>segmentsDistance</th>\n",
       "      <th>segmentsCabinCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e1b137527b9175d7d930c3af82e70ae0</td>\n",
       "      <td>2022-04-19</td>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>OAK</td>\n",
       "      <td>ATL</td>\n",
       "      <td>PT7H52M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>103.98</td>\n",
       "      <td>...</td>\n",
       "      <td>1653107460||1653126600</td>\n",
       "      <td>2022-05-20T22:31:00.000-06:00||2022-05-21T05:5...</td>\n",
       "      <td>DEN||ATL</td>\n",
       "      <td>OAK||DEN</td>\n",
       "      <td>Frontier Airlines||Frontier Airlines</td>\n",
       "      <td>F9||F9</td>\n",
       "      <td>||Airbus A320</td>\n",
       "      <td>9180||10620</td>\n",
       "      <td>943||1207</td>\n",
       "      <td>coach||coach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d813ebd107e3fa700206c0d96015da7a</td>\n",
       "      <td>2022-04-19</td>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>OAK</td>\n",
       "      <td>ATL</td>\n",
       "      <td>PT6H15M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>216.58</td>\n",
       "      <td>...</td>\n",
       "      <td>1653067080||1653084660</td>\n",
       "      <td>2022-05-20T10:18:00.000-07:00||2022-05-20T18:1...</td>\n",
       "      <td>LAX||ATL</td>\n",
       "      <td>OAK||LAX</td>\n",
       "      <td>Spirit Airlines||Spirit Airlines</td>\n",
       "      <td>NK||NK</td>\n",
       "      <td>||AIRBUS INDUSTRIE A320 SHARKLETS</td>\n",
       "      <td>4920||15600</td>\n",
       "      <td>None||None</td>\n",
       "      <td>coach||coach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e8ece5ad6f5962c696e06e031fc2a24a</td>\n",
       "      <td>2022-04-19</td>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>OAK</td>\n",
       "      <td>ATL</td>\n",
       "      <td>PT9H6M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>216.58</td>\n",
       "      <td>...</td>\n",
       "      <td>1653056820||1653084660</td>\n",
       "      <td>2022-05-20T07:27:00.000-07:00||2022-05-20T18:1...</td>\n",
       "      <td>LAX||ATL</td>\n",
       "      <td>OAK||LAX</td>\n",
       "      <td>Spirit Airlines||Spirit Airlines</td>\n",
       "      <td>NK||NK</td>\n",
       "      <td>AIRBUS INDUSTRIE A320 SHARKLETS||AIRBUS INDUST...</td>\n",
       "      <td>4920||15600</td>\n",
       "      <td>None||None</td>\n",
       "      <td>coach||coach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c004a54681335100f326c9613b3c9448</td>\n",
       "      <td>2022-04-19</td>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>OAK</td>\n",
       "      <td>ATL</td>\n",
       "      <td>PT6H17M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>237.58</td>\n",
       "      <td>...</td>\n",
       "      <td>1653110940||1653127980</td>\n",
       "      <td>2022-05-20T22:29:00.000-07:00||2022-05-21T06:1...</td>\n",
       "      <td>LAS||ATL</td>\n",
       "      <td>OAK||LAS</td>\n",
       "      <td>Spirit Airlines||Spirit Airlines</td>\n",
       "      <td>NK||NK</td>\n",
       "      <td>AIRBUS INDUSTRIE A320 SHARKLETS||Airbus A319</td>\n",
       "      <td>5580||13980</td>\n",
       "      <td>None||None</td>\n",
       "      <td>coach||coach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4a42bbf77211b4afa7b9e14005949120</td>\n",
       "      <td>2022-04-19</td>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>OAK</td>\n",
       "      <td>ATL</td>\n",
       "      <td>PT14H12M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>307.21</td>\n",
       "      <td>...</td>\n",
       "      <td>1653115560||1653159180</td>\n",
       "      <td>2022-05-20T23:46:00.000-07:00||2022-05-21T14:5...</td>\n",
       "      <td>SEA||ATL</td>\n",
       "      <td>OAK||SEA</td>\n",
       "      <td>Alaska Airlines||Alaska Airlines</td>\n",
       "      <td>AS||AS</td>\n",
       "      <td>Boeing 737-900||Boeing 737-900</td>\n",
       "      <td>7500||17580</td>\n",
       "      <td>672||2178</td>\n",
       "      <td>coach||coach</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              legId  searchDate  flightDate startingAirport  \\\n",
       "0  e1b137527b9175d7d930c3af82e70ae0  2022-04-19  2022-05-20             OAK   \n",
       "1  d813ebd107e3fa700206c0d96015da7a  2022-04-19  2022-05-20             OAK   \n",
       "2  e8ece5ad6f5962c696e06e031fc2a24a  2022-04-19  2022-05-20             OAK   \n",
       "3  c004a54681335100f326c9613b3c9448  2022-04-19  2022-05-20             OAK   \n",
       "4  4a42bbf77211b4afa7b9e14005949120  2022-04-19  2022-05-20             OAK   \n",
       "\n",
       "  destinationAirport travelDuration  isBasicEconomy  isRefundable  isNonStop  \\\n",
       "0                ATL        PT7H52M           False         False      False   \n",
       "1                ATL        PT6H15M           False         False      False   \n",
       "2                ATL         PT9H6M           False         False      False   \n",
       "3                ATL        PT6H17M           False         False      False   \n",
       "4                ATL       PT14H12M           False         False      False   \n",
       "\n",
       "   totalFare  ...  segmentsArrivalTimeEpochSeconds  \\\n",
       "0     103.98  ...           1653107460||1653126600   \n",
       "1     216.58  ...           1653067080||1653084660   \n",
       "2     216.58  ...           1653056820||1653084660   \n",
       "3     237.58  ...           1653110940||1653127980   \n",
       "4     307.21  ...           1653115560||1653159180   \n",
       "\n",
       "                              segmentsArrivalTimeRaw  \\\n",
       "0  2022-05-20T22:31:00.000-06:00||2022-05-21T05:5...   \n",
       "1  2022-05-20T10:18:00.000-07:00||2022-05-20T18:1...   \n",
       "2  2022-05-20T07:27:00.000-07:00||2022-05-20T18:1...   \n",
       "3  2022-05-20T22:29:00.000-07:00||2022-05-21T06:1...   \n",
       "4  2022-05-20T23:46:00.000-07:00||2022-05-21T14:5...   \n",
       "\n",
       "  segmentsArrivalAirportCode segmentsDepartureAirportCode  \\\n",
       "0                   DEN||ATL                     OAK||DEN   \n",
       "1                   LAX||ATL                     OAK||LAX   \n",
       "2                   LAX||ATL                     OAK||LAX   \n",
       "3                   LAS||ATL                     OAK||LAS   \n",
       "4                   SEA||ATL                     OAK||SEA   \n",
       "\n",
       "                    segmentsAirlineName segmentsAirlineCode  \\\n",
       "0  Frontier Airlines||Frontier Airlines              F9||F9   \n",
       "1      Spirit Airlines||Spirit Airlines              NK||NK   \n",
       "2      Spirit Airlines||Spirit Airlines              NK||NK   \n",
       "3      Spirit Airlines||Spirit Airlines              NK||NK   \n",
       "4      Alaska Airlines||Alaska Airlines              AS||AS   \n",
       "\n",
       "                        segmentsEquipmentDescription  \\\n",
       "0                                      ||Airbus A320   \n",
       "1                  ||AIRBUS INDUSTRIE A320 SHARKLETS   \n",
       "2  AIRBUS INDUSTRIE A320 SHARKLETS||AIRBUS INDUST...   \n",
       "3       AIRBUS INDUSTRIE A320 SHARKLETS||Airbus A319   \n",
       "4                     Boeing 737-900||Boeing 737-900   \n",
       "\n",
       "  segmentsDurationInSeconds segmentsDistance segmentsCabinCode  \n",
       "0               9180||10620        943||1207      coach||coach  \n",
       "1               4920||15600       None||None      coach||coach  \n",
       "2               4920||15600       None||None      coach||coach  \n",
       "3               5580||13980       None||None      coach||coach  \n",
       "4               7500||17580        672||2178      coach||coach  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "def list_csv_files_in_zips(folder_path, max_folders=2):\n",
    "    \"\"\"\n",
    "    Lists all CSV files within the first two ZIP archives in a folder.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): The path to the folder containing ZIP files.\n",
    "    max_folders (int): The maximum number of ZIP folders to process.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary with ZIP file names as keys and a list of CSV file names as values.\n",
    "    \"\"\"\n",
    "    csv_files = {}\n",
    "    folder_count = 0\n",
    "    \n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.zip'):\n",
    "                zip_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                        csv_list = [name for name in zip_ref.namelist() if name.endswith('.csv')]\n",
    "                        if csv_list:\n",
    "                            csv_files[zip_path] = csv_list\n",
    "                            folder_count += 1\n",
    "                            if folder_count >= max_folders:\n",
    "                                return csv_files\n",
    "                except Exception as e:\n",
    "                    csv_files[zip_path] = f\"An error occurred: {e}\"\n",
    "    \n",
    "    return csv_files\n",
    "\n",
    "def merge_csv_files_from_zips_to_dataframe(folder_path, max_folders=2):\n",
    "    \"\"\"\n",
    "    Merges all CSV files within the first two ZIP archives in a folder into one DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): The path to the folder containing ZIP files.\n",
    "    max_folders (int): The maximum number of ZIP folders to process.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the merged data from all CSV files.\n",
    "    \"\"\"\n",
    "    csv_files = list_csv_files_in_zips(folder_path, max_folders)\n",
    "    merged_df = pd.DataFrame()\n",
    "    \n",
    "    for zip_path, csv_list in csv_files.items():\n",
    "        if isinstance(csv_list, list):\n",
    "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                for csv_file in csv_list:\n",
    "                    with zip_ref.open(csv_file) as f:\n",
    "                        df = pd.read_csv(f)\n",
    "                        merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "# Example usage\n",
    "folder_path = '/Users/thusondube/Downloads/itineraries_csv'\n",
    "merged_df = merge_csv_files_from_zips_to_dataframe(folder_path)\n",
    "merged_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b86d4b-5273-4d43-852c-8651bf8a5b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def list_csv_files_in_zips(folder_path):\n",
    "    \"\"\"\n",
    "    Lists all CSV files within multiple ZIP archives in a folder.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): The path to the folder containing ZIP files.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary with ZIP file names as keys and a list of CSV file names as values.\n",
    "    \"\"\"\n",
    "    csv_files = {}\n",
    "    \n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.zip'):\n",
    "                zip_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                        csv_list = [name for name in zip_ref.namelist() if name.endswith('.csv')]\n",
    "                        if csv_list:\n",
    "                            csv_files[zip_path] = csv_list\n",
    "                except Exception as e:\n",
    "                    csv_files[zip_path] = f\"An error occurred: {e}\"\n",
    "    \n",
    "    return csv_files\n",
    "\n",
    "def read_csv_from_zip(zip_path, csv_file):\n",
    "    \"\"\"\n",
    "    Reads a CSV file from a ZIP archive and returns it as a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    zip_path (str): The path to the ZIP file.\n",
    "    csv_file (str): The name of the CSV file within the ZIP archive.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the data from the CSV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            with zip_ref.open(csv_file) as f:\n",
    "                return pd.read_csv(f)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading {csv_file} from {zip_path}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def merge_csv_files_from_zips_to_parquet(folder_path, output_file):\n",
    "    \"\"\"\n",
    "    Merges all CSV files within multiple ZIP archives in a folder into one Parquet file.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): The path to the folder containing ZIP files.\n",
    "    output_file (str): The path to the output Parquet file.\n",
    "    \"\"\"\n",
    "    csv_files = list_csv_files_in_zips(folder_path)\n",
    "    merged_df = pd.DataFrame()\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for zip_path, csv_list in csv_files.items():\n",
    "            if isinstance(csv_list, list):\n",
    "                for csv_file in csv_list:\n",
    "                    futures.append(executor.submit(read_csv_from_zip, zip_path, csv_file))\n",
    "        \n",
    "        for future in futures:\n",
    "            df = future.result()\n",
    "            merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
    "    \n",
    "    merged_df.to_parquet(output_file, engine='pyarrow')\n",
    "    print(f\"All CSV files have been merged and saved to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "folder_path = '/Users/thusondube/Downloads/itineraries_csv'\n",
    "output_file = '/Users/thusondube/Downloads/merged_output.parquet'\n",
    "merge_csv_files_from_zips_to_parquet(folder_path, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b94b6ad-d9f4-4e86-ae3d-dec7f699a775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "\n",
    "# Set the path to the root directory containing the zip files\n",
    "root_dir = '/Users/thusondube/Downloads/itineraries_csv'\n",
    "\n",
    "# Initialize an empty list to hold DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Walk through the root directory\n",
    "for folder_name, subfolders, filenames in os.walk(root_dir):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.zip'):\n",
    "            # Get the full path to the zip file\n",
    "            zip_file_path = os.path.join(folder_name, filename)\n",
    "            \n",
    "            # Open the zip file\n",
    "            with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "                # Loop through files inside the zip and check if it's a CSV\n",
    "                for file in zip_ref.namelist():\n",
    "                    if file.endswith('.csv'):\n",
    "                        # Read the CSV into a DataFrame\n",
    "                        with zip_ref.open(file) as f:\n",
    "                            df = pd.read_csv(f)\n",
    "                            # Append the DataFrame to the list\n",
    "                            df_list.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "merged_df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9278893-153f-40f7-a3ed-c23bd1e6fbaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>legId</th>\n",
       "      <th>searchDate</th>\n",
       "      <th>flightDate</th>\n",
       "      <th>startingAirport</th>\n",
       "      <th>destinationAirport</th>\n",
       "      <th>travelDuration</th>\n",
       "      <th>isBasicEconomy</th>\n",
       "      <th>isRefundable</th>\n",
       "      <th>isNonStop</th>\n",
       "      <th>totalFare</th>\n",
       "      <th>...</th>\n",
       "      <th>segmentsArrivalTimeEpochSeconds</th>\n",
       "      <th>segmentsArrivalTimeRaw</th>\n",
       "      <th>segmentsArrivalAirportCode</th>\n",
       "      <th>segmentsDepartureAirportCode</th>\n",
       "      <th>segmentsAirlineName</th>\n",
       "      <th>segmentsAirlineCode</th>\n",
       "      <th>segmentsEquipmentDescription</th>\n",
       "      <th>segmentsDurationInSeconds</th>\n",
       "      <th>segmentsDistance</th>\n",
       "      <th>segmentsCabinCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e1b137527b9175d7d930c3af82e70ae0</td>\n",
       "      <td>2022-04-19</td>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>OAK</td>\n",
       "      <td>ATL</td>\n",
       "      <td>PT7H52M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>103.98</td>\n",
       "      <td>...</td>\n",
       "      <td>1653107460||1653126600</td>\n",
       "      <td>2022-05-20T22:31:00.000-06:00||2022-05-21T05:5...</td>\n",
       "      <td>DEN||ATL</td>\n",
       "      <td>OAK||DEN</td>\n",
       "      <td>Frontier Airlines||Frontier Airlines</td>\n",
       "      <td>F9||F9</td>\n",
       "      <td>||Airbus A320</td>\n",
       "      <td>9180||10620</td>\n",
       "      <td>943||1207</td>\n",
       "      <td>coach||coach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d813ebd107e3fa700206c0d96015da7a</td>\n",
       "      <td>2022-04-19</td>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>OAK</td>\n",
       "      <td>ATL</td>\n",
       "      <td>PT6H15M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>216.58</td>\n",
       "      <td>...</td>\n",
       "      <td>1653067080||1653084660</td>\n",
       "      <td>2022-05-20T10:18:00.000-07:00||2022-05-20T18:1...</td>\n",
       "      <td>LAX||ATL</td>\n",
       "      <td>OAK||LAX</td>\n",
       "      <td>Spirit Airlines||Spirit Airlines</td>\n",
       "      <td>NK||NK</td>\n",
       "      <td>||AIRBUS INDUSTRIE A320 SHARKLETS</td>\n",
       "      <td>4920||15600</td>\n",
       "      <td>None||None</td>\n",
       "      <td>coach||coach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e8ece5ad6f5962c696e06e031fc2a24a</td>\n",
       "      <td>2022-04-19</td>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>OAK</td>\n",
       "      <td>ATL</td>\n",
       "      <td>PT9H6M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>216.58</td>\n",
       "      <td>...</td>\n",
       "      <td>1653056820||1653084660</td>\n",
       "      <td>2022-05-20T07:27:00.000-07:00||2022-05-20T18:1...</td>\n",
       "      <td>LAX||ATL</td>\n",
       "      <td>OAK||LAX</td>\n",
       "      <td>Spirit Airlines||Spirit Airlines</td>\n",
       "      <td>NK||NK</td>\n",
       "      <td>AIRBUS INDUSTRIE A320 SHARKLETS||AIRBUS INDUST...</td>\n",
       "      <td>4920||15600</td>\n",
       "      <td>None||None</td>\n",
       "      <td>coach||coach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c004a54681335100f326c9613b3c9448</td>\n",
       "      <td>2022-04-19</td>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>OAK</td>\n",
       "      <td>ATL</td>\n",
       "      <td>PT6H17M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>237.58</td>\n",
       "      <td>...</td>\n",
       "      <td>1653110940||1653127980</td>\n",
       "      <td>2022-05-20T22:29:00.000-07:00||2022-05-21T06:1...</td>\n",
       "      <td>LAS||ATL</td>\n",
       "      <td>OAK||LAS</td>\n",
       "      <td>Spirit Airlines||Spirit Airlines</td>\n",
       "      <td>NK||NK</td>\n",
       "      <td>AIRBUS INDUSTRIE A320 SHARKLETS||Airbus A319</td>\n",
       "      <td>5580||13980</td>\n",
       "      <td>None||None</td>\n",
       "      <td>coach||coach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4a42bbf77211b4afa7b9e14005949120</td>\n",
       "      <td>2022-04-19</td>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>OAK</td>\n",
       "      <td>ATL</td>\n",
       "      <td>PT14H12M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>307.21</td>\n",
       "      <td>...</td>\n",
       "      <td>1653115560||1653159180</td>\n",
       "      <td>2022-05-20T23:46:00.000-07:00||2022-05-21T14:5...</td>\n",
       "      <td>SEA||ATL</td>\n",
       "      <td>OAK||SEA</td>\n",
       "      <td>Alaska Airlines||Alaska Airlines</td>\n",
       "      <td>AS||AS</td>\n",
       "      <td>Boeing 737-900||Boeing 737-900</td>\n",
       "      <td>7500||17580</td>\n",
       "      <td>672||2178</td>\n",
       "      <td>coach||coach</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              legId  searchDate  flightDate startingAirport  \\\n",
       "0  e1b137527b9175d7d930c3af82e70ae0  2022-04-19  2022-05-20             OAK   \n",
       "1  d813ebd107e3fa700206c0d96015da7a  2022-04-19  2022-05-20             OAK   \n",
       "2  e8ece5ad6f5962c696e06e031fc2a24a  2022-04-19  2022-05-20             OAK   \n",
       "3  c004a54681335100f326c9613b3c9448  2022-04-19  2022-05-20             OAK   \n",
       "4  4a42bbf77211b4afa7b9e14005949120  2022-04-19  2022-05-20             OAK   \n",
       "\n",
       "  destinationAirport travelDuration  isBasicEconomy  isRefundable  isNonStop  \\\n",
       "0                ATL        PT7H52M           False         False      False   \n",
       "1                ATL        PT6H15M           False         False      False   \n",
       "2                ATL         PT9H6M           False         False      False   \n",
       "3                ATL        PT6H17M           False         False      False   \n",
       "4                ATL       PT14H12M           False         False      False   \n",
       "\n",
       "   totalFare  ...  segmentsArrivalTimeEpochSeconds  \\\n",
       "0     103.98  ...           1653107460||1653126600   \n",
       "1     216.58  ...           1653067080||1653084660   \n",
       "2     216.58  ...           1653056820||1653084660   \n",
       "3     237.58  ...           1653110940||1653127980   \n",
       "4     307.21  ...           1653115560||1653159180   \n",
       "\n",
       "                              segmentsArrivalTimeRaw  \\\n",
       "0  2022-05-20T22:31:00.000-06:00||2022-05-21T05:5...   \n",
       "1  2022-05-20T10:18:00.000-07:00||2022-05-20T18:1...   \n",
       "2  2022-05-20T07:27:00.000-07:00||2022-05-20T18:1...   \n",
       "3  2022-05-20T22:29:00.000-07:00||2022-05-21T06:1...   \n",
       "4  2022-05-20T23:46:00.000-07:00||2022-05-21T14:5...   \n",
       "\n",
       "  segmentsArrivalAirportCode segmentsDepartureAirportCode  \\\n",
       "0                   DEN||ATL                     OAK||DEN   \n",
       "1                   LAX||ATL                     OAK||LAX   \n",
       "2                   LAX||ATL                     OAK||LAX   \n",
       "3                   LAS||ATL                     OAK||LAS   \n",
       "4                   SEA||ATL                     OAK||SEA   \n",
       "\n",
       "                    segmentsAirlineName segmentsAirlineCode  \\\n",
       "0  Frontier Airlines||Frontier Airlines              F9||F9   \n",
       "1      Spirit Airlines||Spirit Airlines              NK||NK   \n",
       "2      Spirit Airlines||Spirit Airlines              NK||NK   \n",
       "3      Spirit Airlines||Spirit Airlines              NK||NK   \n",
       "4      Alaska Airlines||Alaska Airlines              AS||AS   \n",
       "\n",
       "                        segmentsEquipmentDescription  \\\n",
       "0                                      ||Airbus A320   \n",
       "1                  ||AIRBUS INDUSTRIE A320 SHARKLETS   \n",
       "2  AIRBUS INDUSTRIE A320 SHARKLETS||AIRBUS INDUST...   \n",
       "3       AIRBUS INDUSTRIE A320 SHARKLETS||Airbus A319   \n",
       "4                     Boeing 737-900||Boeing 737-900   \n",
       "\n",
       "  segmentsDurationInSeconds segmentsDistance segmentsCabinCode  \n",
       "0               9180||10620        943||1207      coach||coach  \n",
       "1               4920||15600       None||None      coach||coach  \n",
       "2               4920||15600       None||None      coach||coach  \n",
       "3               5580||13980       None||None      coach||coach  \n",
       "4               7500||17580        672||2178      coach||coach  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
